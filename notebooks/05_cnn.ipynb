{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a670302f-1f96-47dc-94e6-893b1378d2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c95b11f-a7e8-4663-a9d5-e808dcbf2236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from dll import utils\n",
    "from dll.models import Classifier\n",
    "from dll.trainer import Trainer\n",
    "from dll.dataloader import FashionMNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99351156-741a-40ab-a0e9-bbdcabe10853",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ac15d2-b9ff-4255-b404-5775bde335ff",
   "metadata": {},
   "source": [
    "## Convolutions for Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f4da52-b069-47a7-bc7b-d3ddf08b03a5",
   "metadata": {},
   "source": [
    "### The Cross-correlation Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58874c5-9db3-4769-b0fa-e97a3f98348d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d(X, K):\n",
    "    \"\"\"Compute 2D cross-correlation.\"\"\"\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd4658f-dd41-4bf4-b13c-6955c4a39324",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
    "corr2d(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51fba06-5b54-40a8-9bbe-28aa631a9c8c",
   "metadata": {},
   "source": [
    "### Convolution Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad173f6-6783-461d-a158-f8b9f05df728",
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv2D(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.rand(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return corr2d(x, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82559bdb-040d-4f63-af63-e13f49b49adf",
   "metadata": {},
   "source": [
    "### Object Edge Detection in Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4f835a-27e8-4bb8-9795-45fe90bbcaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.ones((6, 8))\n",
    "X[:, 2:6] = 0\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a474cd9f-5f11-40a7-af0a-49dae63727df",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = torch.tensor([[1.0, -1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b766564-3121-4c56-b4a4-c5702116de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = corr2d(X, K)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8b2986-29d1-40b9-903c-b22b97258f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr2d(X.t(), K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0556f93-d5ac-4113-b7a8-9b80a1af0986",
   "metadata": {},
   "source": [
    "### Learning a Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dbaf8e-1b80-49ce-b09d-c80b75105c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d = nn.LazyConv2d(1, kernel_size=(1, 2), bias=False)\n",
    "\n",
    "X = X.reshape((1, 1, 6, 8))\n",
    "Y = Y.reshape((1, 1, 6, 7))\n",
    "lr = 3e-2 \n",
    "\n",
    "for i in range(10):\n",
    "    Y_hat = conv2d(X)\n",
    "    l = (Y_hat - Y) ** 2\n",
    "    conv2d.zero_grad()\n",
    "    l.sum().backward()\n",
    "    # Update the kernel\n",
    "    conv2d.weight.data[:] -= lr * conv2d.weight.grad\n",
    "    if (i + 1) % 2 == 0:\n",
    "        print(f'epoch {i + 1}, loss {l.sum():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48841130-9da1-44b6-a97e-fb93f453cd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d.weight.data.reshape((1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046f4420-dc00-48ec-9919-fead6c4954b1",
   "metadata": {},
   "source": [
    "## Padding and Stride"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97379e3f-064b-4250-841e-a2380180e80a",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adbac8b-9532-4152-be55-cd5bd71b11ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_conv2d(conv2d, X):\n",
    "    X = X.reshape((1, 1) + X.shape)\n",
    "    Y = conv2d(X)\n",
    "\n",
    "    return Y.reshape(Y.shape[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb37855-4208-499e-884a-8fbad16a37e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d = nn.LazyConv2d(1, kernel_size=3, padding=1)\n",
    "X = torch.rand(size=(8, 8))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6870dc7-0144-4019-9722-d967f22569ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d = nn.LazyConv2d(1, kernel_size=(5, 3), padding=(2, 1))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753f897e-e620-4694-b052-e8d44e24935d",
   "metadata": {},
   "source": [
    "### Stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a097422-75fc-41f4-8d6c-ded831be3f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d = nn.LazyConv2d(1, kernel_size=3, padding=1, stride=2)\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8751bf9-f77a-43cc-91b8-1b152479c0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d = nn.LazyConv2d(1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4faf88-ac66-4d59-896a-cac6b1848f62",
   "metadata": {},
   "source": [
    "##  Multiple Input and Multiple Output Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75796ee-fd6e-49ff-bd25-54a3be3dc584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in(X, K):\n",
    "    return sum(corr2d(x, k) for x, k in zip(X, K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d7cffe-c3f6-4a2b-b307-12ae777b4b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n",
    "               [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
    "K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n",
    "\n",
    "corr2d_multi_in(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f339b263-866f-430e-abf8-fa5530478f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af52ad1-5272-4a02-afbc-511ad836b862",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = torch.stack((K, K + 1, K + 2), 0)\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f533b32a-a7ec-4ced-a831-86224602cb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr2d_multi_in_out(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e29197d-6636-4844-924d-d365a6994801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out_1x1(X, K):\n",
    "    c_i, h, w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "    X = X.reshape((c_i, h * w))\n",
    "    K = K.reshape((c_o, c_i))\n",
    "    Y = torch.matmul(K, X)\n",
    "    return Y.reshape((c_o, h, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555e469c-74f6-4666-8270-8228fc95edd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.normal(0, 1, (3, 3, 3))\n",
    "K = torch.normal(0, 1, (2, 3, 1, 1))\n",
    "Y1 = corr2d_multi_in_out_1x1(X, K)\n",
    "Y2 = corr2d_multi_in_out(X, K)\n",
    "assert float(torch.abs(Y1 - Y2).sum()) < 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8abd4bb-a70e-4fea-bd06-2edc0ec78150",
   "metadata": {},
   "source": [
    "## Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4044b087-a040-4671-b79e-d684708b2440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool2d(X, pool_size, mode='max'):\n",
    "    p_h, p_w = pool_size\n",
    "    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].max()\n",
    "            elif mode == 'avg':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c196ea83-90a7-4fce-8786-6bffc7a42aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "pool2d(X, (2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3a5a77-f53d-441c-a57b-3bc1f851026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool2d(X, (2, 2), 'avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c30eaad-a195-4eb5-be31-d4bdb921e80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6af8c50-22bf-4a05-bd9a-73d147e28ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool2d = nn.MaxPool2d(3)\n",
    "\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859f2587-4c29-4dc3-b2e6-36c7e52392f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf1afd1-fb0e-44e2-97ab-0a9c589167de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool2d = nn.MaxPool2d((2, 3), stride=(2, 3), padding=(0, 1))\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134ad055-0c3f-47c5-830f-853ce5a2e3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.cat((X, X + 1), 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d634af0-a8bb-4cb6-897a-77a438bd084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45749676-0a00-4217-a5c7-156ca52838a5",
   "metadata": {},
   "source": [
    "## LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d5d2be-52f9-43f5-8c70-0f8dbfe34225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_cnn(module):\n",
    "    \"\"\"Initialize weights for CNNs.\"\"\"\n",
    "    if type(module) == nn.Linear or type(module) == nn.Conv2d:\n",
    "        nn.init.xavier_uniform_(module.weight)\n",
    "\n",
    "class LeNet(Classifier):\n",
    "    \"\"\"The LeNet-5 model.\"\"\"\n",
    "    def __init__(self, lr=0.1, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyConv2d(6, kernel_size=5, padding=2), nn.Sigmoid(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.LazyConv2d(16, kernel_size=5), nn.Sigmoid(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(120), nn.Sigmoid(),\n",
    "            nn.LazyLinear(84), nn.Sigmoid(),\n",
    "            nn.LazyLinear(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be5b7f2-bf00-42f8-88af-6a4f70633dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@utils.add_to_class(Classifier)\n",
    "def layer_summary(self, X_shape):\n",
    "    X = torch.rand(*X_shape)\n",
    "    for layer in self.net:\n",
    "        X = layer(X)\n",
    "        print(layer.__class__.__name__, 'output shape: \\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b0fc2b-a161-421e-8b4b-ed119578160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet()\n",
    "model.layer_summary((1, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e945679-2c38-4d8c-b734-f12c182f2080",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(max_epochs=10, num_gpus=0)\n",
    "data = FashionMNIST(batch_size=128)\n",
    "model = LeNet(lr=0.01)\n",
    "model.apply_init([next(iter(data.get_dataloader(True)))[0]], init_cnn)\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebcea22-b265-4a63-8f6d-99be294894e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "ai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
