{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a670302f-1f96-47dc-94e6-893b1378d2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c95b11f-a7e8-4663-a9d5-e808dcbf2236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from dll import utils\n",
    "from dll.models import Classifier, init_cnn\n",
    "from dll.trainer import Trainer\n",
    "from dll.dataloader import FashionMNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99351156-741a-40ab-a0e9-bbdcabe10853",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ac15d2-b9ff-4255-b404-5775bde335ff",
   "metadata": {},
   "source": [
    "## Convolutions for Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f4da52-b069-47a7-bc7b-d3ddf08b03a5",
   "metadata": {},
   "source": [
    "### The Cross-correlation Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58874c5-9db3-4769-b0fa-e97a3f98348d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d(X, K):\n",
    "    \"\"\"Compute 2D cross-correlation.\"\"\"\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd4658f-dd41-4bf4-b13c-6955c4a39324",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
    "corr2d(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51fba06-5b54-40a8-9bbe-28aa631a9c8c",
   "metadata": {},
   "source": [
    "### Convolution Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad173f6-6783-461d-a158-f8b9f05df728",
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv2D(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.rand(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return corr2d(x, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82559bdb-040d-4f63-af63-e13f49b49adf",
   "metadata": {},
   "source": [
    "### Object Edge Detection in Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4f835a-27e8-4bb8-9795-45fe90bbcaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.ones((6, 8))\n",
    "X[:, 2:6] = 0\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a474cd9f-5f11-40a7-af0a-49dae63727df",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = torch.tensor([[1.0, -1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b766564-3121-4c56-b4a4-c5702116de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = corr2d(X, K)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8b2986-29d1-40b9-903c-b22b97258f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr2d(X.t(), K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0556f93-d5ac-4113-b7a8-9b80a1af0986",
   "metadata": {},
   "source": [
    "### Learning a Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dbaf8e-1b80-49ce-b09d-c80b75105c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d = nn.LazyConv2d(1, kernel_size=(1, 2), bias=False)\n",
    "\n",
    "X = X.reshape((1, 1, 6, 8))\n",
    "Y = Y.reshape((1, 1, 6, 7))\n",
    "lr = 3e-2 \n",
    "\n",
    "for i in range(10):\n",
    "    Y_hat = conv2d(X)\n",
    "    l = (Y_hat - Y) ** 2\n",
    "    conv2d.zero_grad()\n",
    "    l.sum().backward()\n",
    "    # Update the kernel\n",
    "    conv2d.weight.data[:] -= lr * conv2d.weight.grad\n",
    "    if (i + 1) % 2 == 0:\n",
    "        print(f'epoch {i + 1}, loss {l.sum():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48841130-9da1-44b6-a97e-fb93f453cd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d.weight.data.reshape((1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046f4420-dc00-48ec-9919-fead6c4954b1",
   "metadata": {},
   "source": [
    "## Padding and Stride"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97379e3f-064b-4250-841e-a2380180e80a",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adbac8b-9532-4152-be55-cd5bd71b11ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_conv2d(conv2d, X):\n",
    "    X = X.reshape((1, 1) + X.shape)\n",
    "    Y = conv2d(X)\n",
    "\n",
    "    return Y.reshape(Y.shape[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb37855-4208-499e-884a-8fbad16a37e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d = nn.LazyConv2d(1, kernel_size=3, padding=1)\n",
    "X = torch.rand(size=(8, 8))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6870dc7-0144-4019-9722-d967f22569ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d = nn.LazyConv2d(1, kernel_size=(5, 3), padding=(2, 1))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753f897e-e620-4694-b052-e8d44e24935d",
   "metadata": {},
   "source": [
    "### Stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a097422-75fc-41f4-8d6c-ded831be3f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d = nn.LazyConv2d(1, kernel_size=3, padding=1, stride=2)\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8751bf9-f77a-43cc-91b8-1b152479c0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d = nn.LazyConv2d(1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4faf88-ac66-4d59-896a-cac6b1848f62",
   "metadata": {},
   "source": [
    "##  Multiple Input and Multiple Output Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75796ee-fd6e-49ff-bd25-54a3be3dc584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in(X, K):\n",
    "    return sum(corr2d(x, k) for x, k in zip(X, K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d7cffe-c3f6-4a2b-b307-12ae777b4b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n",
    "               [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
    "K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n",
    "\n",
    "corr2d_multi_in(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f339b263-866f-430e-abf8-fa5530478f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af52ad1-5272-4a02-afbc-511ad836b862",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = torch.stack((K, K + 1, K + 2), 0)\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f533b32a-a7ec-4ced-a831-86224602cb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr2d_multi_in_out(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e29197d-6636-4844-924d-d365a6994801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out_1x1(X, K):\n",
    "    c_i, h, w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "    X = X.reshape((c_i, h * w))\n",
    "    K = K.reshape((c_o, c_i))\n",
    "    Y = torch.matmul(K, X)\n",
    "    return Y.reshape((c_o, h, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555e469c-74f6-4666-8270-8228fc95edd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.normal(0, 1, (3, 3, 3))\n",
    "K = torch.normal(0, 1, (2, 3, 1, 1))\n",
    "Y1 = corr2d_multi_in_out_1x1(X, K)\n",
    "Y2 = corr2d_multi_in_out(X, K)\n",
    "assert float(torch.abs(Y1 - Y2).sum()) < 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8abd4bb-a70e-4fea-bd06-2edc0ec78150",
   "metadata": {},
   "source": [
    "## Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4044b087-a040-4671-b79e-d684708b2440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool2d(X, pool_size, mode='max'):\n",
    "    p_h, p_w = pool_size\n",
    "    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].max()\n",
    "            elif mode == 'avg':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c196ea83-90a7-4fce-8786-6bffc7a42aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "pool2d(X, (2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3a5a77-f53d-441c-a57b-3bc1f851026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool2d(X, (2, 2), 'avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c30eaad-a195-4eb5-be31-d4bdb921e80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6af8c50-22bf-4a05-bd9a-73d147e28ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool2d = nn.MaxPool2d(3)\n",
    "\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859f2587-4c29-4dc3-b2e6-36c7e52392f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf1afd1-fb0e-44e2-97ab-0a9c589167de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool2d = nn.MaxPool2d((2, 3), stride=(2, 3), padding=(0, 1))\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134ad055-0c3f-47c5-830f-853ce5a2e3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.cat((X, X + 1), 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d634af0-a8bb-4cb6-897a-77a438bd084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45749676-0a00-4217-a5c7-156ca52838a5",
   "metadata": {},
   "source": [
    "## LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d5d2be-52f9-43f5-8c70-0f8dbfe34225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_cnn(module):\n",
    "    \"\"\"Initialize weights for CNNs.\"\"\"\n",
    "    if type(module) == nn.Linear or type(module) == nn.Conv2d:\n",
    "        nn.init.xavier_uniform_(module.weight)\n",
    "\n",
    "class LeNet(Classifier):\n",
    "    \"\"\"The LeNet-5 model.\"\"\"\n",
    "    def __init__(self, lr=0.1, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyConv2d(6, kernel_size=5, padding=2), nn.Sigmoid(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.LazyConv2d(16, kernel_size=5), nn.Sigmoid(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(120), nn.Sigmoid(),\n",
    "            nn.LazyLinear(84), nn.Sigmoid(),\n",
    "            nn.LazyLinear(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be5b7f2-bf00-42f8-88af-6a4f70633dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@utils.add_to_class(Classifier)\n",
    "def layer_summary(self, X_shape):\n",
    "    X = torch.rand(*X_shape)\n",
    "    for layer in self.net:\n",
    "        X = layer(X)\n",
    "        print(layer.__class__.__name__, 'output shape: \\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b0fc2b-a161-421e-8b4b-ed119578160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet()\n",
    "model.layer_summary((1, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e945679-2c38-4d8c-b734-f12c182f2080",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(max_epochs=10, num_gpus=0)\n",
    "data = FashionMNIST(batch_size=128)\n",
    "model = LeNet(lr=0.01)\n",
    "model.apply_init([next(iter(data.get_dataloader(True)))[0]], init_cnn)\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf3ccc5-28eb-4d3e-8731-2e7af4d13915",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3438405-f720-4e5a-8970-e1c17d75aab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(Classifier):\n",
    "    def __init__(self, lr=0.1, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyConv2d(96, kernel_size=11, stride=4, padding=1),\n",
    "            nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.LazyConv2d(256, kernel_size=5, padding=2), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.LazyConv2d(384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.LazyConv2d(384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.LazyConv2d(256, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2), nn.Flatten(),\n",
    "            nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(p=0.5),\n",
    "            nn.LazyLinear(4096), nn.ReLU(),nn.Dropout(p=0.5),\n",
    "            nn.LazyLinear(num_classes))\n",
    "        self.net.apply(d2l.init_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6616e64-0768-4575-b3ae-d2207a37364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AlexNet().layer_summary((1, 1, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347aaa78-32d9-4ba4-92f2-ed04df08ce4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlexNet(lr=0.01)\n",
    "data = FashionMNIST(batch_size=128, resize=(224, 224))\n",
    "trainer = Trainer(max_epochs=10, num_gpus=1)\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b64376c-55d9-480e-b6ce-39f714d334bb",
   "metadata": {},
   "source": [
    "## Networks Using Blocks (VGG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8883a5e0-a713-45f0-a901-cbd45efd6ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_block(num_convs, out_channels):\n",
    "    layers = []\n",
    "    for _ in range(num_convs):\n",
    "        layers.append(nn.LazyConv2d(out_channels, kernel_size=3, padding=1))\n",
    "        layers.append(nn.ReLU())\n",
    "    layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "    return nn.Sequenctial(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349cc639-1919-481c-b935-f329469a5fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(Classifier):\n",
    "    def __ini__(self, arch, lr=0.1, num_classes=10):\n",
    "        super().__ini__()\n",
    "        self.save_hyperparameters()\n",
    "        conv_blks = []\n",
    "        for (num_convs, out_channels) in arch:\n",
    "            conv_blks.append(vgg_block(num_convs, out_channels))\n",
    "        self.net = nn.Sequential(\n",
    "            *conv_blks, nn.Flatten(),\n",
    "            nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.LazyLinear(num_classes))\n",
    "        self.net.apply(init_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54984b6-8f7d-4192-bf53-c457816b48bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG(arch=((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))).layer_summary(\n",
    "    (1, 1, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf047ce-47a4-4f72-91fd-434565797bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG(arch=((1, 16), (1, 32), (2, 64), (2, 128), (2, 128)), lr=0.01)\n",
    "trainer = Trainer(max_epochs=10, num_gpus=1)\n",
    "data = FashionMNIST(batch_size=128, resize=(224, 224))\n",
    "model.apply_init([next(iter(data.get_dataloader(True)))[0]], init_cnn)\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca57ce42-9417-49ce-bf38-f4c7d8c2da58",
   "metadata": {},
   "source": [
    "## Network in Network (NiN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3031c301-2f41-4f52-87d3-1ce2f9b2567b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nin_block(out_channels, kernel_size, strides, padding):\n",
    "    return nn.Sequential(\n",
    "        nn.LazyConv2d(out_channels, kernel_size, strides, padding), nn.ReLU(),\n",
    "        nn.LazyConv2d(out_channels, kernel_size=1), nn.ReLU(),\n",
    "        nn.LazyConv2d(out_channels, kernel_size=1), nn.ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb44e0f-fecf-4909-8296-f5107f1b6e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NiN(Classifier):\n",
    "    def __init__(self, lr=0.1, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.net = nn.Sequential(\n",
    "            nin_block(96, kernel_size=11, strides=4, padding=0),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            nin_block(256, kernel_size=5, strides=1, padding=2),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            nin_block(384, kernel_size=3, strides=1, padding=1),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            nn.Dropout(0.5),\n",
    "            nin_block(num_classes, kernel_size=3, strides=1, padding=1),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten())\n",
    "        self.net.appy(init_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9124dab8-0427-48fb-9e83-8dd8d206b244",
   "metadata": {},
   "outputs": [],
   "source": [
    "NiN().layer_summary((1, 1, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef60ae33-1026-4c2e-9285-5a07c3a5ef94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NiN(lr=0.05)\n",
    "trainer = Trainer(max_epochs=10, num_gpus=1)\n",
    "data = FashionMNIST(batch_size=128, resize=(224, 224))\n",
    "model.apply_init([next(iter(data.get_dataloader(True)))[0]], init_cnn)\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8944488a-91de-45df-9184-7cb4b5b6369e",
   "metadata": {},
   "source": [
    "## Multi-Branch Networks (GoogLeNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f29a794-578a-4aaa-a8cd-4514edb0c14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    def __init__(self, c1, c2, c3, c4, **kwargs):\n",
    "        super(Inception, self).__init__(**kwargs)\n",
    "        self.b1_1 = nn.LazyConv2d(c1, kernel_size=1)\n",
    "        self.b2_1 = nn.LazyConv2d(c2[0], kernel_size=1)\n",
    "        self.b2_2 = nn.LazyConv2d(c2[1], kernel_size=3, padding=1)\n",
    "        self.b3_1 = nn.LazyConv2d(c3[0], kernel_size=1)\n",
    "        self.b3_2 = nn.LazyConv2d(c3[1], kernel_size=5, padding=2)\n",
    "        self.b4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.b4_2 = nn.LazyConv2d(c4, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b1 = F.relu(self.b1_1(x))\n",
    "        b2 = F.relu(self.b2_2(F.relu(self.b2_1(x))))\n",
    "        b3 = F.relu(self.b3_2(F.relu(self.b3_1(x))))\n",
    "        b4 = F.relu(self.b4_2(self.b4_1(x)))\n",
    "        return torch.cat((b1, b2, b3, b4), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3b0d06-cbf6-495a-805d-f39f80d7881b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogleNet(Classifier):\n",
    "    def __init__(self, lr=0.1, num_classes=10):\n",
    "        super(GoogleNet, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.net = nn.Sequential(self.b1(), self.b2(), \n",
    "                                 self.b3(), self.b4(),\n",
    "                                 self.b5(), nn.LazyLinear(num_classes))\n",
    "        self.net.apply(d2l.init_cnn)\n",
    "\n",
    "    \n",
    "    def b1(self):\n",
    "        return nn.Sequential(\n",
    "            nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "    def b2(self):\n",
    "        return nn.Sequential(\n",
    "            nn.LazyConv2d(64, kernel_size=1), nn.ReLU(),\n",
    "            nn.LazyConv2d(192, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "    def b3(self):\n",
    "        return nn.Sequential(Inception(64, (96, 128), (16, 32), 32),\n",
    "            Inception(128, (128, 192), (32, 96), 64),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "    def b4(self):\n",
    "        return nn.Sequential(Inception(192, (96, 208), (16, 48), 64),\n",
    "             Inception(160, (112, 224), (24, 64), 64),\n",
    "             Inception(128, (128, 256), (24, 64), 64),\n",
    "             Inception(112, (144, 288), (32, 64), 64),\n",
    "             Inception(256, (160, 320), (32, 128), 128),\n",
    "             nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "    def b5(self):\n",
    "        return nn.Sequential(Inception(256, (160, 320), (32, 128), 128),\n",
    "            Inception(384, (192, 384), (48, 128), 128),\n",
    "            nn.AdaptiveAvgPool2d((1,1)), nn.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ed670b-eabf-4386-afd2-ceeaa5d84f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GoogleNet().layer_summary((1, 1, 96, 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4a1b2a-de3e-49eb-9ed1-765196e2b315",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GoogleNet(lr=0.01)\n",
    "trainer = Trainer(max_epochs=10, num_gpus=1)\n",
    "data = FashionMNIST(batch_size=128, resize=(96, 96))\n",
    "model.apply_init([next(iter(data.get_dataloader(True)))[0]], init_cnn)\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8efc93-df75-4b43-a3ad-977893d32f04",
   "metadata": {},
   "source": [
    "## Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b7ba21-5c7b-468b-a290-23f5984af49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm(X, gamma, beta, moving_mean, moving_var, eps, momentum):\n",
    "    if not torch.is_grad_enabled():\n",
    "        X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)\n",
    "    else:\n",
    "        assert len(X.shape) in (2, 4)\n",
    "        if len(X.shape) == 2:\n",
    "            mean = X.mean(dim=0)\n",
    "            var = ((X - mean) ** 2).mean(dim=0)\n",
    "        else:\n",
    "            mean = X.mean(dim=(0, 2, 3), keepdim=True)\n",
    "            var = ((X - mean) ** 2).mean(dim=0, 2, 3), keepdim=True)\n",
    "        X_hat = (X - mean) / torch.sqrt(var + eps)\n",
    "        moving_mean = (1. - momentum) * moving_mean + momentum * mean\n",
    "        moving_var = (1. - momentum) * moving_var + momentum * var\n",
    "    Y = gamma * X_hat + beta\n",
    "    return Y, moving_mean.data, moving_var.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d118fb9-d520-404a-a65e-488672e0e94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    def __ini__(self, num_featues, num_dims):\n",
    "        super().__init__()\n",
    "        if num_dims == 2:\n",
    "            shape = (1, num_features)\n",
    "        else:\n",
    "            shape = (1, num_features)\n",
    "        self.gamma = nn.Parameter(torch.ones(shape))\n",
    "        self.beta = nn.Parameter(torch.zeros(shape))\n",
    "\n",
    "    def forward(self, X):\n",
    "        if self.moving_mean.device != X.device:\n",
    "            self.moving_mean = self.moving_mean.to(X.device)\n",
    "            self.moving_var = self.moving_var.ro(X.device)\n",
    "        Y, self.moving_mean, self.mocing_var = barch_norm(\n",
    "            X, self.gamma, self.beta, self.moving_mean,\n",
    "            self.moving_var, eps=1e-5, momentum=0.1)\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfefa307-2050-4e45-ba19-71136d4548f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNLeNetScratch(Classifier):\n",
    "    def __init__(self, lr=0.1, num_classes=10):\n",
    "        super().__ini__()\n",
    "        self.save_hyperparameters()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyConv2d(6, kernel_size=5), BatchNorm(6, num_dims=4),\n",
    "            nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.LazyConv2d(16, kernel_size=5), BatchNorm(16, num_dims=4),\n",
    "            nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(), nn.LazyLinear(120),\n",
    "            BatchNorm(120, num_dims=2), nn.Sigmoid(), nn.LazyLinear(84),\n",
    "            BatchNorm(84, num_dims=2), nn.Sigmoid(),\n",
    "            nn.LazyLinear(num_classes)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140761fd-17b1-42ae-8e7b-46f48af61b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(max_epochs=10, num_gpus=1)\n",
    "data = FashionMNIST(batch_size=128)\n",
    "model = BNLeNetScratch(lr=0.1)\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6672c1f9-2efa-4994-9841-02cd60bb4630",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.net[1].gamma.reshape((-1,)), model.net[1].beta.reshape((-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e3d934-bfb3-4d45-bc74-a9756cfb5fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNLeNet(Classifier):\n",
    "    def __init__(self, lr=0.1, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyConv2d(6, kernel_size=5), nn.LazyBatchNorm2d(),\n",
    "            nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.LazyConv2d(16, kernel_size=5), nn.LazyBatchNorm2d(),\n",
    "            nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(), nn.LazyLinear(120), nn.LazyBatchNorm1d(),\n",
    "            nn.Sigmoid(), nn.LazyLinear(84), nn.LazyBatchNorm1d(),\n",
    "            nn.Sigmoid(), nn.LazyLinear(num_classes)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d77da3-1db2-4349-85ed-4ab1ef89bfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(max_epochs=10, num_gpus=1)\n",
    "data = FashionMNIST(batch_size=128)\n",
    "model = BNLeNet(lr=0.1)\n",
    "model.apply_init([next(iter(data.get_dataloader(True)))[0]], init_cnn)\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad1d7bd-da5d-4f56-a364-e548d7564bd6",
   "metadata": {},
   "source": [
    "## Residual Networks (ResNet) and ResNeXt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fac4a0-794a-4bf1-a22e-808d5775e258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "ai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
